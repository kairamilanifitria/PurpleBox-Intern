{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "104kL32YRzVbz1mx0KYU5qvoe-dwprwer",
      "authorship_tag": "ABX9TyOFJlMpvVUDst03WsxI0ADo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kairamilanifitria/PurpleBox-Intern/blob/main/RAG/5_RETRIEVAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "import json\n",
        "import numpy as np\n",
        "import re\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "def query_supabase(user_query):\n",
        "    \"\"\"Retrieves both text and table chunks based on query, using improved embeddings.\"\"\"\n",
        "\n",
        "    #### Step 1: Get Query Embedding ####\n",
        "    query_embedding = np.array(get_embedding(user_query), dtype=np.float32).flatten()\n",
        "\n",
        "    #### Step 2: Retrieve Text Chunks (Vector Search) ####\n",
        "    response_text = supabase.table(\"documents\").select(\"chunk_id, content, embedding, type, metadata\").execute()\n",
        "    text_results = []\n",
        "\n",
        "    for record in response_text.data:\n",
        "        chunk_embedding = record[\"embedding\"]\n",
        "\n",
        "        # Convert stored string embeddings to list if needed\n",
        "        if isinstance(chunk_embedding, str):\n",
        "            chunk_embedding = ast.literal_eval(chunk_embedding)\n",
        "\n",
        "        chunk_embedding = np.array(chunk_embedding, dtype=np.float32).flatten()\n",
        "\n",
        "        if chunk_embedding.shape == query_embedding.shape:\n",
        "            similarity = 1 - cosine(query_embedding, chunk_embedding)\n",
        "            text_results.append((record[\"chunk_id\"], \"text\", record[\"content\"], similarity))\n",
        "\n",
        "    #### Step 3: Retrieve Table Chunks (Description + Embedding Match) ####\n",
        "    response_tables = supabase.table(\"tables\").select(\"chunk_id, table_data, description, embedding, metadata\").execute()\n",
        "    table_results = []\n",
        "\n",
        "    for record in response_tables.data:\n",
        "        table_data = record[\"table_data\"]\n",
        "        metadata = record.get(\"metadata\", {})\n",
        "        table_description = record.get(\"description\", \"\")  # Use generated description\n",
        "        table_embedding = record.get(\"embedding\", None)\n",
        "\n",
        "        # Ensure metadata fields are strings\n",
        "        table_title = str(metadata.get(\"table_title\", \"\"))\n",
        "        section = str(metadata.get(\"section\", \"\"))\n",
        "\n",
        "        # Extract table number from the query (if any)\n",
        "        table_number_match = re.search(r'table (\\d+)', user_query, re.IGNORECASE)\n",
        "        specified_table_number = table_number_match.group(1) if table_number_match else None\n",
        "\n",
        "        # Step 3.1: Keyword Matching for Table Title, Section & Description\n",
        "        keyword_match_score = 0\n",
        "        if re.search(rf\"\\b{re.escape(user_query)}\\b\", table_title, re.IGNORECASE):\n",
        "            keyword_match_score += 0.5  # Higher weight for title match\n",
        "        if re.search(rf\"\\b{re.escape(user_query)}\\b\", section, re.IGNORECASE):\n",
        "            keyword_match_score += 0.3  # Lower weight for section match\n",
        "        if re.search(rf\"\\b{re.escape(user_query)}\\b\", table_description, re.IGNORECASE):\n",
        "            keyword_match_score += 0.7  # Highest weight for description match\n",
        "\n",
        "        # Prioritize the exact table number if mentioned\n",
        "        if specified_table_number and specified_table_number in table_title.lower():\n",
        "            keyword_match_score += 1.0  # Give a strong boost to matching table numbers\n",
        "\n",
        "        # Step 3.2: Compute Embedding Similarity\n",
        "        if table_embedding:\n",
        "            if isinstance(table_embedding, str):\n",
        "                table_embedding = ast.literal_eval(table_embedding)  # Convert string to list\n",
        "            table_embedding = np.array(table_embedding, dtype=np.float32).flatten()\n",
        "\n",
        "            if table_embedding.shape == query_embedding.shape:\n",
        "                similarity = 1 - cosine(query_embedding, table_embedding)\n",
        "                final_score = (0.7 * similarity) + (1.3 * keyword_match_score)  # Boost keyword matching\n",
        "                table_results.append((record[\"chunk_id\"], \"table\", table_description, final_score))\n",
        "\n",
        "    #### Step 4: Merge & Sort Results ####\n",
        "    all_results = text_results + table_results\n",
        "    all_results.sort(key=lambda x: x[3], reverse=True)  # Sort by final similarity score\n",
        "\n",
        "    return all_results[:5]  # Return top 5 results\n"
      ],
      "metadata": {
        "id": "TR-X3TndSUcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_query = \"___________\"\n",
        "retrieved_chunks = query_supabase(user_query)\n",
        "\n",
        "for chunk in retrieved_chunks:\n",
        "    print(f\"Chunk ID: {chunk[0]}\\nType: {chunk[1]}\\nContent: {chunk[2][:300]}...\\nRelevance: {chunk[3]:.4f}\\n\")\n"
      ],
      "metadata": {
        "id": "NpEt-IJxSUfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "this retrieval code only show 5 most relevant chunks. Not connected with LLM. See next section in section `6_LLM.ipynb` for combine the retrieval and LLM prompting."
      ],
      "metadata": {
        "id": "gZS5PqlSS4iP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "this code can't be run and tested until it connected to the supabase API"
      ],
      "metadata": {
        "id": "vm9CoJ9XThoX"
      }
    }
  ]
}